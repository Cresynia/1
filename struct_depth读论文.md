

# StructDepth: Leveraging the structural regularities for self-supervised indoor depth extimation利用结构规律进行自我监督的室内深度估计

![image-20230317102345681](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230317102345681.png)

# Abstract

  在户外的数据集上，自监督单目深度估计已经取得了令人影响深刻的性能。然而，**（==面临的问题==）由于缺乏纹理**，自监督单目深度估计的性能在室内显著下降。如果缺乏纹理信息，光度损失的约束性能就会下降，无法训练出好的深度网络。受早期室内建模工作的影响，**本文利用室内场景中表现出来的结构规律**，训练出更好的网络。==**总体来说，采用了两个额外的监督信号来进行自监督训练：（1）曼哈顿平面法向量约束（ the Manhattan normal constraint）和（2）局部共平面约束（ the co-planar constraint）**==。其中，曼哈顿约束强制使得主要表面（如地面、天花板和墙壁等）与主导方向对齐。平面约束表明，如果三维点位于同一个平面区域内，他们将被同一个平面很好地拟合。**在训练过程中，本文采用两个分量将主表面法线划分为主导方向，并在飞行中检测出平面区域，从而产生监督信号**。在训练过程中，随着训练时间的延长，预测的深度变的更加精准，监督信号也得到改善，反过来监督信号也更好的约束网络用来得到更好的深度信息。通过在室内基准数据集上的大量实验，结果表明，我们的网络的性能优于最先进的方法。

# 1. Introduction

  在深度估计发展之前，从单一图像推断**密集的三维地图**一直是一个难以令人满意的问题。利用深度卷积网络（CNN），我们可以通过训练网络，使用大量地面真值标签从单个图像中预测准确的深度。近年来自监督单目深度估计不需要地面真值，**使用光度一致性作为主要的监督信号**，仍然在基准数据集上获得高质量的结果。然而，**当现有的室外的深度估计转移到室内时，深度估计的性能明显下降**。==其中主要原因是室内环境缺少纹理信息（问题）==。与室外不同，室内充满了无纹理区域，如白色的墙壁，天花板和地板等。由于缺失丰富的纹理，光度损失的监督效果会明显下降，以至于无法训练出良好的模型。**因此，为了训练一个良好的深度估计网络，必须要寻找更强或者额外的监督信号。（目标）**
  在此之前有一些其他方法。利用稀疏SURF（Speeded up robust features，加强特征流）通过自监督网络传播的光流场对无纹理区域进行引导训练。一些方法使用**图像补丁**而不是单个像素来计算光度损失，并对分割后提取的平面区域的深度施加额外的约束。尽管这些方法改善了深度估计的结果，**但是他们没有充分的利用室内环境中呈现的结构规律，而结构规律是3D学习的一个宝贵信息来源**。结构规律被称为曼哈顿-世界模型，描述了场景由与主导方向对齐的主要平面组成。这种简单有效的高阶先验可以在许多视觉任务中获得更好的表现，如室内建模、视觉SLAM和视觉测距但尚未应用于单目深度估计。
  在本研究中，我们提出将室内结构规律的高阶先验应用于自监督单目深度估计（见图一）。

![image-20230317104953149](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230317104953149.png)

具体来说，我们采用两个额外的监督信号进行训练：1.曼哈顿法向约束和2.局部平面约束。曼哈顿约束强制主要表面和主导方向对齐。平面约束表明，如果三维点在同一个平面区域内，他们将被一个平面很好的拟合。

**我们将==两个额外的组件==添加到培训过程中。**

第一个是曼哈顿法向量检测，它从网络预测的深度中计算出主要的表面法线，并通过自适应阈值方案将其分割为与消失点相关的方向。

第二种是平面区域检测。我们融合了颜色和由深度得到的几何信息，并采用经典的分割算法提取平面区域。

在训练过程中，这两个部分结合估计出的深度，在训练过程中产生监督信号。这些信号在早期可能会因为深度估计不准确而产生噪声，但随着深度质量的提升，这些信号会逐渐改善，从而有利于深度估计。
  本文在**室内基准数据集：NYU-v2、ScanNet和InteriorNet上进行实验**。结果表明，我们的方法优于最优的结果。我们的主要贡献如下。

（1）首次利用室内环境结构规律来约束自监督深度估计网络。

一种利用室内环境的结构规律的自监督深度估计学习管道。据我们所知，这一点在以前的工作中并没有提出过

（2）采用曼哈顿约束和平面约束来提高额外的约束信号。

两个新的组件在训练过程中提供额外的监控信号。我们的组件可以用于训练多任务网络，包括深度估计、正态估计和平面自监督区域检测，尽管后两个任务在我们当前的实现中有助于训练更好的深度模型。

（3）一种新的室内自监督深度估计网络框架，效果良好。

我们建立了一个新的最先进的自监督室内深度估计。

# 2. Related work

## monocular depth estimation

  单目深度估计是一个极其难以解决的不适定问题。人们提出了很多方法来提高单目深度估计的精度，其中大多数是需要地面真实深度数据进行训练的有监督的方法。
  由于大规模的获取地面真实深度具有挑战性，所以不需要真值的自监督单目深度估计得到了广泛的关注。

Godard提出的mono中，首次引入图像来代替地面真实深度来训练深度网络，在一对立体图像中，**一个图像被预测的深度图扭曲到另一个视图，通过计算合成图像和真实图像之间的差异，即光度误差，来约束网络的训练过程**。目前，这个思路被广泛的用于自监督深度估计，人们通过设计网络结构，修改损失函数以及在线优化等方式，使自监督深度估计的精度不断地提高。
  现有的自监督方法在室外数据集上取得了令人影响深刻的性能，但在室内数据集上表现不佳。**原因是室内场景充满了无纹理区域，例如白色的墙壁和天花板，使得光度损失的约束性受到干扰**,zhou等人通过光流的的流场监督，初始化SURF通信。最近的工作采用了更有分辨率的补丁而不是单个的像素来计算光度损失，但是这些方法都没有充分的利用环境的结构。

## Planar region detection

  平面区域检测，虽然最近提出了一些平面区域探测器，但是这些探测器需要大量的**平面标签**来进行训练，不适合自监督深度估计，本文所使用的是一个04年经典的基于图像分割的方法来检测平面区域(和P2Net的图像分割方法一样)，同时利用**从深度中提取的附加几何信息进行训练时的动态估计**，在附加几何信息的基础上，**==(我们做的优点)==避免了以前只依靠颜色来区分平面的现象，减少了错误平面的产生以及对纹理丰富区域的过度分割**。

## Structural regularities in indoor environments

  室内环境的结构规律。室内场景表现出强烈的结构规律，可以称之为曼哈顿世界。这些场景可以分为主要的平面，这些平面的法向量相互正交。这些结构规律是有价值的先验，已经广泛的用于室内三维重建任务，例如SLAM、VIO和映射。事实上，在早期的研究中，**利用室内场景的结构先验**可能是从单个图像中推断3D信息的唯一几何方法。研究人员认为，在室内环境中，结构规律也应该利于基于学习的视觉任务。Wang等人提出使用消失点和消失线来训练表面法向估计器，本文的方法和他们类似，但不同的是，表面法向只作为一个中间结果，我们的主要任务是深度估计，此外，**我们的深度网络完全采用自监督的方式**，不需要线图来作为额外的输入。据本文作者说，他们是**第一个将室内环境的==结构规律==用于自监督单目深度估计。**


# 3. Method

![image-20230317121237411](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230317121237411.png)

上图是本文的自监督框架，主要由三部分组成。

1.DepthNet进行深度图的预测。

2.Manhattan法向检测，将深度图预测出的表面法向分为**主导方向**。---别人写的，我觉得不准确，见下面。

3.平面区域检测，通过基于图像的分割方法，**利用颜色和几何信息来提取平面区域**。

由上述的2和3所增加了两个额外的约束，即曼哈顿损失和平面损失，如上图的红色箭头所示。

***

我们的自监督深度学习管道如图2所示。它由三个主要的组成部分组成。第一个是深度网络，它以单个图像作为输入，并预测一个深度图。我们对深度网络使用与[50，P2NET]中相同的架构。在预测深度的基础上，利用曼哈顿法线检测和平面区域检测这两个分量，利用室内环境的结构先验产生监测信号。

曼哈顿法线检测将**从深度图计算出的法线**与**从图像中的消失点估计出的主导方向**对齐（可以根据图来理解）。

平面区域检测**采用基于图的分割方法**，**结合颜色、法线和平面到原点的距离信息**来检测平面区域。

曼哈顿法态检测和平面区域检测在初始训练阶段可能不准确，但随着深度预测的提高会有所改善。改进的监控信号也导致了更好的深度预测。

在下面的章节中，我们将描述我们如何在训练过程中应用曼哈顿法线约束和局部共平面约束。

==总结来说，就是两部分：法线约束，平面约束。==

## 3.1 Manhattan normal constraint

### 1.Dominant direction extraction----主方向提取

  从室内的结构环境来看，大多数的**室内场景都包含着延主导方向排列的平面**。**==主方向==可以由图像中的==结构线==来估计**。图像中一组**平行结构线**的交点为**==消失点==**。

设v为二维图像中的消失点。相机坐标系中的一个==主导方向==被计算为

**η ∝ K^−1^v** ==（为什么是这个公式，还没有研究过！）==

其中η ∈ R^3^表示这个主导方向的单位向量，K是相机的内参矩阵。

我们**只需要两个消失点就可以计算==所有的主导方向==**，因为第三个主导方向可以通过叉乘得到（这里讲的应该是三维坐标系他采用两条相交线确定一个平面，通过两条线叉乘得到垂直于平面的另一个坐标轴，以此来确定坐标系），我们采用==**两线搜索法[33]**==提取图像中的主导方向，**主方向的提取只在网路训练前提取一次**（应该是每一张图片进入网络前都提取一次）。
  **提取的方向和反方向都被认为是场景中的主要平面（类似于天花板、地板和墙壁）可能的法线方向**。

### 2.Surface normal estimation----表面法向量估计

> **我的思考与总结**
>
> ==这一部分主要是对法向量的估计，要如何估计呢？==
>
> 1.depthnet预测得到的深度图---->得到图片每个像素点p的三维坐标Xp
>
> 2.有了三维坐标Xp以后------>根据三维坐标估计法线------->怎么估计？------>==lego方法,需要具体去研究(这里利用了以Xp为中心的一个小领域得到的法向量)==

为了估计曲面法线，我们首先通过预测的深度图像得到每个像素点p的三维坐标Xp

即**==Xp=D(p)K^-1^p==**

其中，D(p)为预测的深度图。

接下来，我们采用了一种可微的point-to-normal的方法，即根据三维点去估计法线（==Lego==）。其中给定的像素点p的法向量n~p~是根据三维点Xp为中心的一个小领域计算得到的。该邻域大小为7×7。根据之前的工作[46lego]

### 3.Manhattan normal detection----曼哈顿法向量检测

  在给定曲面法线预测n的情况下，本文提出了曼哈顿法线检测方法来**==对属于主导平面的曲面法线进行分类==**。

我们的方法是利用**余弦相似度**来比较估计出的法向量n~p~和每个主导方向η^k^之间的差异，并选择具有最佳相似度的那个**==主导方向记为n~p~^align^==**。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230317213315932.png" alt="image-20230317213315932" style="zoom:50%;" />

  余弦相似度度量公式如下。

<img src="https://img-blog.csdnimg.cn/0dda2186c09e44efb04c2107e894c5a4.png" alt="img" style="zoom:50%;" />

设每个像素的**最大相似度为s~p~^max^** ，定义曼哈顿区域选择公式如下，取决于余弦相似度和阈值γ。

<img src="https://img-blog.csdnimg.cn/a6f7dd2ed56245db8d2f837379a527e7.png" alt="在这里插入图片描述" style="zoom:50%;" />

> **我的理解：**
>
> 即当主方向与估计出来的法向量非常相似（什么是非常相似？-----就是大于阈值γ的时候），就可以认为该点为曼哈顿区域。

在训练过程中，我们使用一个**自适应阈值方案**来检测曼哈顿区域。我们最初设置了一个相对较小的阈值，以允许更多的像素被分类到曼哈顿区域，并逐渐增加阈值，因为随着训练轮数的增多，法向量估计变得更加准确。  

在我们的研究中，设置阈值γ随着训练次数N^train^呈线性增长： **γ = α·N^train^ + β**，其中α和β分别设置为1.633e^−3^和0.9。（==为什么要这样设置呢，这个问题需要解决！==）

### 4.Manhattan normal loss----曼哈顿法向量损失

我们利用图3中得到的对齐法线作为监督信号，在曼哈顿区域内应用曼哈顿法向量约束。该约束使得估计的法线尽可能接近对齐的法线，由损失函数L~norm~来描述：

<img src="https://img-blog.csdnimg.cn/a46a227ce90443aaa4c8ae39d23f7b72.png" alt="在这里插入图片描述" style="zoom:50%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230317214955542.png" alt="image-20230317214955542" style="zoom:70%;" />

其中，N~norm~是位于曼哈顿区域的像素数，M~P~^p^表示像素p是否位于平面区域，我们将在下一节中介绍检测平面区域的方法。

## 3.2 Co-planar constraint

### 1.Planar region detection----平面区域检测  

为了加强共面约束，我们需要正确的检测出平面区域，之前的方法通过**==假设颜色均匀的区域来检测平面区域（P2net的做法）==**。但是这样简单的策略**==会导致错误的检测或者过度分割产生错误的监督信号（面对的问题）==**，我们（==**我们的方法**==）提出了一种**采用==颜色不相似度和几何信息不相似度==的新的平面区域检测的方法**。见图三。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230318103213258.png" alt="image-20230318103213258" style="zoom:67%;" />

**平面区域检测的管道。**利用颜色信息和几何信息来计算平面区域分割的不相似度。颜色的不相似度是通过比较RGB的颜色来计算的。几何不相似度是**法线距离差异**和**平面到原点距离不相似度**的和。基于所提出的差异，采用**基于图的分割[11]**来提取平面区域。

> 什么是normal dissimilarity and plane-to-origin distance dissimilarity

关键思想是，在接下来的基于图的分割中，我们采用了一种**新的不相似度**。这种不相似度**考虑了颜色、法线和平面到原点的距离**。我们**使用==对齐的法线==来推导不相似度**，而不是估计的法线，因为我们发现后者太嘈杂了。

设一个像素点p的三维坐标为Xp。假设这个三维点Xp**位于平面**上，且它匹配的平面法线为n~p~^align^（即可认为与之匹配的法线就是该平面的法线）。

则从该平面到原点的距离为==（为什么呢？？？）==

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230318161147227.png" alt="image-20230318161147227" style="zoom:50%;" />

  假设q为p的相邻像素点，p和q的**==法向==不相似度**定义为**p和q所对应的两个法向向量n~p~^align^和n~q~^align^之间的欧氏距离。**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230318162002911.png" alt="image-20230318162002911" style="zoom:70%;" />

  使用D~n~^min^和D~n~^max^来表示所有相邻像素中的最小法向不相似度和最大法向不相似度，并定义一个**[·]**运算符来对不相似度进行归一化。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230318162302603.png" alt="image-20230318162302603" style="zoom:80%;" />

  平面到原点的**==距离==不相似度**定义如下。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230318162344944.png" alt="image-20230318162344944" style="zoom: 67%;" />

总体的**==几何不相似度==**是结合了【平面到原点的距离】与【法向】不相似度归一化后的结果。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230318162744313.png" alt="image-20230318162744313" style="zoom:80%;" />

颜色不相似度公式如下，其中I~p~，I~q~是RGB的颜色（==这里应该也是计算了欧氏距，但公式里的xyz换成了rgb，？？？？？？==）

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230318162902472.png" alt="image-20230318162902472" style="zoom:80%;" />

最后，结合了颜色信息和几何信息的不相似度度量公式如下。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230318163153286.png" alt="image-20230318163153286" style="zoom:67%;" />

基于不同的差异，我们应用基于图的分割[11]，滤除小区域，得到平面区域。（根据P2net里的方法）用这种不相似度定义方法的优点可以见图4。

![image-20230318163914911](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230318163914911.png)

提出了在训练过程中进行的平面区域检测。从左到右的列：输入图像、真实深度、估计深度、差异图，以及仅通过颜色[50]检测到的平面区域，以及我们基于颜色和几何信息的方法检测出的平面区域。**第一行：两面墙==不能用颜色来区分==，但可以用我们的方法来分开。第二行：地板通过只使用颜色而==被过度分割==**，**但通过我们的方法可以正确地检测到**。

==【我们方法带来的好处】==与仅使用颜色信息相比，我们的方法避免了因无法通过颜色来区分而产生的错误平面区域，也避免了由不同颜色造成的过度分割。

注意到，我们的平面区域分割是在训练过程中被更新的。随着训练的进行，深度准确度的逐渐提高带来了更好的分割，反之亦然。

### 2.Generate the co-planar depth----生成共平面深度

在检测到平面区域后，我们调用共面约束来使位于这些平面区域内的**三维点变平**-----就是使得位于同一个平面的点都在同一平面上。

第一步是对平面区域内的三维点进行平面拟合。

通过求解最小二乘问题

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230318170827918.png" alt="image-20230318170827918" style="zoom: 80%;" />

我们得到了平面参数**θ=−n/d∈R^3^**（在先前的工作28，50，p2net里），其中，X∈R^3×N^的每一列代表平面区域内的一个三维点。

然后，通过平面拟合计算像素p的**逆深度ρ~p~**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230318171332528.png" alt="image-20230318171332528" style="zoom:80%;" />

其中，K表示照相机的内参矩阵。然后，我们根据之前的工作[19,20,50]使用最大最小保护将逆深度转换为深度      D~p~^plane^。即可求得共面深度D~p~^plane^。

> 共面深度的计算（看了半天原来就是翻过来再翻过去），首先通过X^T^θ公式将三维点抹平到同一个平面上，采用θ来存储反深度（这里我想了半天，其实就是要想抹平就把深度都乘到1就行了，就是把平面上的所有点的深度都变为1，例如p点和q点的深度分别为3和2，那么θ里面存储的是1/3和1/2就行了，也就是反深度）。

  重点是这里，X原来其实是输入图像加相机内参加预测的深度得到的（这里就不放图了，防止大家混乱），如果只是为了求解共面深度D~p~^plane^其实公式里面直接采用X^T^就可以了，但是为了拉大共面深度和预测深度的不同，所以用θ^T^来计算。其实这都无所谓，重点是这里的p已经不是输入图像了，而是共面约束后的图像，也就是进行了图像分割后的输入图像，这是共面深度和预测深度的本质不同。------==没看懂，再来看看==。



### 3.Co-planar loss----共平面损失

利用平面拟合得到的深度D~p~^plane^作为一个额外的监督信号来约束估计的深度。损失函数的定义为

【共面深度和预测深度】

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230318172643110.png" alt="image-20230318172643110" style="zoom:80%;" />

其中，N~plane~是平面区域M^P^内的像素数。



> ==别人的观点，需要思考的问题==
>
> 他的创新点到这就结束了，个人感觉工作量还是比较大的，但是有个比较严重的问题，曼哈顿约束和共面约束的本质都是在假设法线足够好或者预测深度有效，作者在开始也说，约束能力在初期不好，后续不断变好，但这个其实还是会有一定的负面影响，因为预测的深度始终是不完美的，深度预测错误的区域会直接干扰整个网络的训练，但这个问题文中没有详细描述。



##  3.3Total loss

我们使用图像补丁（image patches）而不是单个像素来计算光度损失（**可以参考P2net**），它定义为**L1损失和结构相似性损失SSIM[55]**的组合：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230318215953746.png" alt="image-20230318215953746" style="zoom:67%;" />

其中，Np表示p像素点周围的局部窗口，

(==我现在的猜测，就是不是以单个像素点去求地光度损失，而是由一个图像补丁，一块局部窗口区域去求光度损失，好处在哪里？？？==///可能是为了避免单一像素点地错误？？？想的不是特别明白！)

ω为两部分的相对权重，设为0.85，与之前的工作[20，monodepth2]相同。我们也采用了**边缘平滑损失（edge-aware smoothness loss）**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230319110442532.png" alt="image-20230319110442532" style="zoom:80%;" />

其中，ρ~t~为逆深度
$$

ρ~t~←ρ~t~/\overline{ρ~t~}
$$
转换为**均值归一化逆深度**，∂x，∂y为沿x和y方向的梯度。

==**总损失的定义为**==

![image-20230319111704668](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230319111704668.png)

λ~1~、λ~2~和λ~3~分别设置为0.001、0.05、0.1。==（为什么这样设置呢？？？）==

# 4.Experimental results

我们在NYUv2数据集[40]上训练我们的模型，使用与之前的工作（[50,53]P2net）相同的数据划分方法，并在NYUv2[40]、ScanNet[7]和InteriorNet[29]数据集上评估我们的方法。==**我们检测到训练图像上的消失点，并跳过18个无法检测到有效消失点的图像序列**。**结果得到21465个单眼训练序列和654张图像进行验证（有点没太明白）**==。每个单目训练序列由五帧组成。（21465个单眼训练序列，每个序列5帧，一共21465*5？）我们的**网络模型**采用了与[50，P2Net]相同的体系结构。

我们将我们的方法与最先进的单目深度估计方法进行了比较。除了深度估计外，我们还评估了表面法线估计的性能，并提出了关于所提监控信号的有效性的消融研究，**并使用了不同的网络架构**。更多的结果可以在**补充材料**中找到。

## 4.1. Implementation details

基于[50，P2net]**预先训练好的模型**，该网络共训练了50轮，批量大小设置为32个。

我们使用了**Adam优化器和一个多步学习率降低策略**（multi-step learning rate reduction strategy）。我们将初始学习速率设置为10^−4^，然后在第26轮和第36轮进行衰减0.1倍。

我们在训练过程中进行**随机翻转和颜色增强**。

所有的图像先不进行处理，从边界处裁剪16个像素，然后**缩放到288×384分辨率**进行训练。==**相机的内参**==来自于官方规格[40]，并被调整为与图像的裁剪和缩放相一致。

我们遵循与[20,50，monodepth2，P2net]中相同的**评估标准**。

并且，我们将深度限制在10m，并采用中值尺度策略，以避免单目深度估计的尺度模糊性。

评价指标包括**均方根误差（RMS）**、**绝对相对误差（AbsRel）**、**平均log10误差（Log10）**和**阈值下的精度（δ~i~ < 1.25^i^，i = 1,2,3）。**

## 4.2. Results on NYUv2 Dataset

### 1.Depth estimation

深度估计的定量结果列于表1中。

![image-20230319120131864](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230319120131864.png)

表1 在NYUv2数据集上的深度估计结果

前两个块列出了有监督方法的结果。第二个块包含**具有平面检测的监督方法**。第三个和第四个块列出了自监督方法的结果。↓表示越低越好，↑表示越高越好。我们的方法在自我监督的方法中表现最好。

==关于post processing????还有我训练出来的和他的结果并不是很好==

***

结果表明，该方法在室内单目深度估计方面大大优于现有的室内自监督估计方法（MovingIndoor[53]和P2Net[50]）。结果还表明，我们的方法优于一些有监督的方法。

深度估计结果如图5所示。

![image-20230319121629976](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230319121629976.png)

图5 在NYUv2数据集上进行可视化，深度结果在左列上，曲面法线结果在右列上。给出了Monodepth2[20]、P2Net[50]和地面真实深度/法线的结果进行比较。与P2Net[50]和Monodepth2[20]相比，我们的方法得到了更好的表面法线和深度估计，如红色矩形所示。定量结果可以看表1，2。

***

可以看出，我们的方法比现有方法获得更准确的室内结构和更平滑的平面。（的确，还是很牛逼的！）

### 2.Surface normal estimation

我们还评估了表面法线估计，见表2。

![image-20230319122844412](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230319122844412.png)

表2

我们的方法优于现有的方法，以及一些有监督的方法[13,35,15]。结果见图5。

![image-20230319122813180](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230319122813180.png)

图5

## 4.3. Results on ScanNet and InteriorNet

我们使用仅在NYUv2上训练的模型，**推广到其他室内数据集**（ScanNet and InteriorNet）来评估我们的方法。

### 1.ScanNet

ScanNet[7]是用iPad上的深度摄像头拍摄的，包含在1513个场景中拍摄的约2.5M==(250万段???)==RGBD视频。我们使用了[50]提出的测试分割，其中包括533张图像。

评价结果如表3所示以及图6。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230319143057900.png" alt="image-20230319143057900" style="zoom: 50%;" />

表3

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230319143151624.png" alt="image-20230319143151624" style="zoom:67%;" />

图6

### 2.InteriorNet

InteriorNet是一个室内视频序列的合成数据集，包含数百万个精心设计的室内设计布局、家具和对象模型。由于目前在InteriorNet上**还没有官方的训练/测试分割**来进行深度估计，所以在这里，**我们从完整数据集的HD7数据中随机选择了540张图像作为测试图像。**

评价结果见表4和图7。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230319144202546.png" alt="image-20230319144202546" style="zoom:67%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230319144224742.png" alt="image-20230319144224742" style="zoom:67%;" />

### 3.ScanNet and Interior上的generalization

虽然没有使用ScanNet以及InteriorNet进行训练，但结果表明，我们的方法仍然具有很好的推广性，优于现有的方法。

## 4.4. Ablation study

### 1.对于Normal/Co-planar 分别/共同研究

为了更好地知道我们方法的有效性，我们在NYUv2数据集上改变我们模型的不同组成部分进行消融研究。我们使用[50]提出的预训练模型初始化网络，并用提出的监督信号对其进行训练。结果见表5。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230319145724909.png" alt="image-20230319145724909" style="zoom:50%;" />

表5

关于使用不同监督信号的消融研究。我们仅使用曼哈顿法线约束（仅法线）、仅使用共面约束（仅共面）和所提出的方法来评估性能。我们还给出了微调后的P2网络模型的结果。**注意，所有的模型都是用相同数量的轮数进行训练的，以便进行公平的比较。**（==这句话看起来感觉很不对，这样怎么能够说是公平呢？==）

***

无论是曼哈顿法线损失还是共面损失，都能使深度估计的结果优于原始的方法和原始的微调方法。将它们结合在一起可以获得最大的性能收益。

### 2.将两种损失用于不同网络结构进行研究

我们还使用**不同的网络结构**来测试我们的方法。见表6。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230319150758170.png" alt="image-20230319150758170" style="zoom:60%;" />

表6 关于使用不同的网络体系结构的消融研究。我们额外的训练损失改进了这两个模型，表明我们的方法对不同的体系结构是通用的。

***

利用所提出的两种监督信号，两种模型都得到了改进，表明我们的方法对不同的网络架构是通用的。但基于Monodepth2的结果比基于P2Net的结果更差。这在很大程度上是由于[50，P2Net]中提出的**基于补丁的光度损失**对**于处理室内环境中无纹理区域**的效果更好。

## 4.5. Planar-region detection in training

我们在图8中显示了**训练过程中的中间平面区域检测结果**。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230319151802154.png" alt="image-20230319151802154" style="zoom:70%;" />

结果表明，随着深度的更新和法线估计的增加，平面区域分割逐渐改善。相比之下，纯颜色的方法会产生如图中由红色矩形圈出来的错误平面区域。

# 5.Limitation

我们将讨论一下我们的方法的局限性。

第一个限制是，**提取主导方向高度依赖于曼哈顿世界的假设**。它在包含不规则倾斜平面的室内场景不能表现良好。可能的解决方案包括使用像[38，56]中那样假设的曼哈顿世界松弛版本，或者直接使用来自每个检测到的消失点的估计方向来推导法向约束。换句话说，这些主导方向并不局限于相互垂直的方向。

第二个限制是**应避免初始深度的低质量**。由于我们的平面区域检测依赖于深度信息，低深度质量会恶化分割结果，产生错误的监督信号，从而阻止网络收敛到一个好的模型。==【我们的解决方案】==是使用**预先训练过的深度模型**或在前面的训练轮中只用光度损失以及平滑损失训练模型。**对于低质量的初始深度估计，设计一个更好的平面区域探测器是待解决的问题。**

# 6.Conclusion

在本文中，我们提出利用**室内环境的结构规律**来进行单目深度估计。两个额外的损失，曼哈顿法线损失和共面损失，被用来监督深度学习。这些监督信号是在训练过程中通过曼哈顿法线检测和平面区域检测**动态产生**的。我们的方法在室内基准数据集上取得了最先进的结果。

# 参考学习文章

https://zhuanlan.zhihu.com/p/522507697

https://blog.csdn.net/SHS_JAVA/article/details/123200127
